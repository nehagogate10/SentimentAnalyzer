{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a4b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import collections\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c0508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_reviews_unclean = []\n",
    "list_of_labels = []\n",
    "tar = tarfile.open(\"../Data/review_polarity.tar.gz\", \"r:gz\")\n",
    "counter = 0\n",
    "\n",
    "# looping through folder, \n",
    "# putting all review strings in list_of_reviews_unclean & all labels in another list_of_labels\n",
    "for member in tar.getmembers():\n",
    "    # checking that it's a normal txt file\n",
    "    if member.isreg():\n",
    "        temp_array = (member.name).split(\"/\")\n",
    "        if (len(temp_array) >= 2):\n",
    "            list_of_labels.append(temp_array[1])\n",
    "            f = tar.extractfile(member)\n",
    "            f_str = f.read().lower().decode(\"utf-8\")\n",
    "            list_of_reviews_unclean.append(f_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "002d2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_num(s):\n",
    "    if re.search(r'\\d', s):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cde29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CLEANING and PREPROCESSING THE DATA\n",
    "#  1. Removing punctuation\n",
    "#  2. Using PorterStemmer for stemming\n",
    "#  3. Removing stop words\n",
    "#  4. Removing words with length <= 2\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "list_of_reviews = []\n",
    "\n",
    "for review in list_of_reviews_unclean:\n",
    "    word_tokens = tokenizer.tokenize(review)\n",
    "    preprocessed_sentence = [stemmer.stem(w.strip(\"_\")) for w in word_tokens if ((not w.lower() in stop_words) and (len(w)>2) and (check_if_num(w)==False) and (any([c!='_' for c in w]))  )]\n",
    "    list_of_reviews.append(' '.join(preprocessed_sentence))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c0c0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_night_at_the_roxburi left exactli'\n",
      " 'a_night_at_the_roxburi take alreadi' 'aaa minor leagu' ...\n",
      " 'zyci master beauti' 'zyci zyci master' 'zzzzzzz critiqu pretti']\n"
     ]
    }
   ],
   "source": [
    "## Using CountVectorizer\n",
    "analyzer=stemmed_words\n",
    "CountVec = CountVectorizer(ngram_range=(3,3))\n",
    "X = CountVec.fit_transform(list_of_reviews)\n",
    "# print(CountVec.get_feature_names_out())\n",
    "cv_dataframe=pd.DataFrame(X.toarray(), columns=CountVec.get_feature_names_out())\n",
    "print((CountVec.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dc680fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function borrowed from TA demo to take as input training and testing vectors and labels\n",
    "\n",
    "def buildClassifiers(clf, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91fb5aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAUSSIAN NAIVE BAYES: \n",
      "\tf1:  0.6979891276085939\n",
      "\tprecision:  0.6980285161063193\n",
      "\trecall:  0.698\n",
      "\taccuracy:  0.698\n"
     ]
    }
   ],
   "source": [
    "########### GAUSSIAN NAIVE BAYES ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# Naive Bayes \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy \n",
    "f1, precision, recall = buildClassifiers(GaussianNB(), X_train, X_test, y_train, y_test )\n",
    "print(\"GAUSSIAN NAIVE BAYES: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c56fce38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD CLASSIFIER: \n",
      "\tf1:  0.6516300473135005\n",
      "\tprecision:  0.6667005540588624\n",
      "\trecall:  0.6574386711686483\n",
      "\taccuracy:  0.634\n"
     ]
    }
   ],
   "source": [
    "########### SGD Classifier ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# SGD Classifier \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier(loss = \"log_loss\")\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy\n",
    "f1, precision, recall = buildClassifiers(SGDClassifier(loss = \"log_loss\"), X_train, X_test, y_train, y_test )\n",
    "print(\"SGD CLASSIFIER: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8868a02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCEPTRON: \n",
      "\tf1:  0.6606060606060606\n",
      "\tprecision:  0.6633553362525325\n",
      "\trecall:  0.6604712378017463\n",
      "\taccuracy:  0.664\n"
     ]
    }
   ],
   "source": [
    "########### PERCEPTRON ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# Perceptron \n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "classifier = Perceptron()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy\n",
    "f1, precision, recall = buildClassifiers(Perceptron(), X_train, X_test, y_train, y_test )\n",
    "print(\"PERCEPTRON: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762614b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
