{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically make functions for every feature\n",
    "# then do the leave one out thing: call all functions but one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc02035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import collections\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d89a48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing list of uncleaned reviews, list of labels (neg or pos) according to which folder the file is in\n",
    "\n",
    "list_of_reviews_unclean = []\n",
    "list_of_labels = []\n",
    "tar = tarfile.open(\"../Data/review_polarity.tar.gz\", \"r:gz\")\n",
    "counter = 0\n",
    "\n",
    "# looping through folder, \n",
    "# putting all review strings in list_of_reviews_unclean & all labels in another list_of_labels\n",
    "for member in tar.getmembers():\n",
    "    # checking that it's a normal txt file\n",
    "    if member.isreg():\n",
    "        temp_array = (member.name).split(\"/\")\n",
    "        # appending review string to list_of_reviews\n",
    "        # adding folder name from file path to list_of_labels\n",
    "        if (len(temp_array) >= 2):\n",
    "            list_of_labels.append(temp_array[1])\n",
    "            f = tar.extractfile(member)\n",
    "            f_str = f.read().lower().decode(\"utf-8\")\n",
    "            list_of_reviews_unclean.append(f_str)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5d52af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function created to check whether a token is a number\n",
    "def check_if_num(s):\n",
    "    if re.search(r'\\d', s):\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c05e079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(check_if_num(\"___\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e773e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CLEANING and PREPROCESSING THE DATA\n",
    "#  1. Removing punctuation\n",
    "#  2. Using PorterStemmer for stemming\n",
    "#  3. Removing stop words\n",
    "#  4. Removing words with length <= 2\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "list_of_reviews = []\n",
    "\n",
    "for review in list_of_reviews_unclean:\n",
    "    word_tokens = tokenizer.tokenize(review)\n",
    "    # remove punctuation, stemming, removing stop words, removing words with length <= 2\n",
    "    preprocessed_sentence = [stemmer.stem(w.strip(\"_\")) for w in word_tokens if ((not w.lower() in stop_words) and (len(w)>2) and (check_if_num(w)==False) and (any([c!='_' for c in w]))  )]\n",
    "    list_of_reviews.append(' '.join(preprocessed_sentence))\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97d38b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_night_at_the_roxburi' 'aaa' 'aaaaaaaaah' ... 'zwigoff' 'zyci'\n",
      " 'zzzzzzz']\n"
     ]
    }
   ],
   "source": [
    "## Using CountVectorizer\n",
    "analyzer=stemmed_words\n",
    "CountVec = CountVectorizer(ngram_range=(1,1))\n",
    "X = CountVec.fit_transform(list_of_reviews)\n",
    "cv_dataframe=pd.DataFrame(X.toarray(), columns=CountVec.get_feature_names_out())\n",
    "print((CountVec.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2057b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function borrowed from TA demo to take as input training and testing vectors and labels\n",
    "\n",
    "def buildClassifiers(clf, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    return f1, precision, recall\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc62db18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAUSSIAN NAIVE BAYES: \n",
      "\tf1:  0.635947576451009\n",
      "\tprecision:  0.6363927650234704\n",
      "\trecall:  0.6362356179289818\n",
      "\taccuracy:  0.636\n"
     ]
    }
   ],
   "source": [
    "########### GAUSSIAN NAIVE BAYES ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# Naive Bayes \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy \n",
    "f1, precision, recall = buildClassifiers(GaussianNB(), X_train, X_test, y_train, y_test )\n",
    "print(\"GAUSSIAN NAIVE BAYES: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4454c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE CLASSIFIER: \n",
      "\tf1:  0.617876191886171\n",
      "\tprecision:  0.6184463222584982\n",
      "\trecall:  0.6187370650238244\n",
      "\taccuracy:  0.618\n"
     ]
    }
   ],
   "source": [
    "########### Decision Tree Classifier ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# Decision Tree Classifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(random_state=0, criterion='gini')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy\n",
    "f1, precision, recall = buildClassifiers(DecisionTreeClassifier(random_state=0, criterion='gini'), X_train, X_test, y_train, y_test )\n",
    "print(\"DECISION TREE CLASSIFIER: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6ad24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD CLASSIFIER: \n",
      "\tf1:  0.8357871801855206\n",
      "\tprecision:  0.8363895974715632\n",
      "\trecall:  0.8356142456982794\n",
      "\taccuracy:  0.832\n"
     ]
    }
   ],
   "source": [
    "########### SGD Classifier ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# SGD Classifier \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier(loss = \"log_loss\")\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy\n",
    "f1, precision, recall = buildClassifiers(SGDClassifier(loss = \"log_loss\"), X_train, X_test, y_train, y_test )\n",
    "print(\"SGD CLASSIFIER: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37352f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION: \n",
      "\tf1:  0.8238195912614518\n",
      "\tprecision:  0.824187627246349\n",
      "\trecall:  0.8236894757903162\n",
      "\taccuracy:  0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "########### Logistic Regression ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# Logistic Regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(solver = \"saga\")\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy\n",
    "f1, precision, recall = buildClassifiers(LogisticRegression(solver = \"saga\"), X_train, X_test, y_train, y_test )\n",
    "print(\"LOGISTIC REGRESSION: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9719ffe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCEPTRON: \n",
      "\tf1:  0.7982927498346001\n",
      "\tprecision:  0.7987878787878788\n",
      "\trecall:  0.7979019964872138\n",
      "\taccuracy:  0.8\n"
     ]
    }
   ],
   "source": [
    "########### PERCEPTRON ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# Perceptron \n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "classifier = Perceptron()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy\n",
    "f1, precision, recall = buildClassifiers(Perceptron(), X_train, X_test, y_train, y_test )\n",
    "print(\"PERCEPTRON: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740d945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d570ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
