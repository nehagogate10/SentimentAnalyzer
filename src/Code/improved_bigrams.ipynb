{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5164f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import collections\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ebd2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_reviews_unclean = []\n",
    "list_of_labels = []\n",
    "tar = tarfile.open(\"../Data/review_polarity.tar.gz\", \"r:gz\")\n",
    "counter = 0\n",
    "\n",
    "# looping through folder, \n",
    "# putting all review strings in list_of_reviews_unclean & all labels in another list_of_labels\n",
    "for member in tar.getmembers():\n",
    "    # checking that it's a normal txt file\n",
    "    if member.isreg():\n",
    "        temp_array = (member.name).split(\"/\")\n",
    "        if (len(temp_array) >= 2):\n",
    "            list_of_labels.append(temp_array[1])\n",
    "            f = tar.extractfile(member)\n",
    "            f_str = f.read().lower().decode(\"utf-8\")\n",
    "            list_of_reviews_unclean.append(f_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe0e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_num(s):\n",
    "    if re.search(r'\\d', s):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b68423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CLEANING and PREPROCESSING THE DATA\n",
    "#  1. Removing punctuation\n",
    "#  2. Using PorterStemmer for stemming\n",
    "#  3. Removing stop words\n",
    "#  4. Removing words with length <= 2\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "list_of_reviews = []\n",
    "\n",
    "for review in list_of_reviews_unclean:\n",
    "    word_tokens = tokenizer.tokenize(review)\n",
    "    preprocessed_sentence = [stemmer.stem(w.strip(\"_\")) for w in word_tokens if ((not w.lower() in stop_words) and (len(w)>2) and (check_if_num(w)==False) and (any([c!='_' for c in w]))  )]\n",
    "    list_of_reviews.append(' '.join(preprocessed_sentence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7270d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_night_at_the_roxburi left' 'a_night_at_the_roxburi take' 'aaa minor'\n",
      " ... 'zyci master' 'zyci zyci' 'zzzzzzz critiqu']\n"
     ]
    }
   ],
   "source": [
    "## Using CountVectorizer\n",
    "analyzer=stemmed_words\n",
    "CountVec = CountVectorizer(ngram_range=(2,2))\n",
    "X = CountVec.fit_transform(list_of_reviews)\n",
    "# print(CountVec.get_feature_names_out())\n",
    "cv_dataframe=pd.DataFrame(X.toarray(), columns=CountVec.get_feature_names_out())\n",
    "print((CountVec.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe5166b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function borrowed from TA demo to take as input training and testing vectors and labels\n",
    "\n",
    "def buildClassifiers(clf, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    return f1, precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e31ce63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAUSSIAN NAIVE BAYES: \n",
      "\tf1:  0.7563617765857626\n",
      "\tprecision:  0.759090909090909\n",
      "\trecall:  0.7558553359303612\n",
      "\taccuracy:  0.758\n"
     ]
    }
   ],
   "source": [
    "########### GAUSSIAN NAIVE BAYES ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# Naive Bayes \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy \n",
    "f1, precision, recall = buildClassifiers(GaussianNB(), X_train, X_test, y_train, y_test )\n",
    "print(\"GAUSSIAN NAIVE BAYES: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b6e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE CLASSIFIER: \n",
      "\tf1:  0.579326923076923\n",
      "\tprecision:  0.5869362516562792\n",
      "\trecall:  0.5854270145151179\n",
      "\taccuracy:  0.58\n"
     ]
    }
   ],
   "source": [
    "########### Decision Tree Classifier ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# Decision Tree Classifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(random_state=0, criterion='gini')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy\n",
    "f1, precision, recall = buildClassifiers(DecisionTreeClassifier(random_state=0, criterion='gini'), X_train, X_test, y_train, y_test )\n",
    "print(\"DECISION TREE CLASSIFIER: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cb37010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD CLASSIFIER: \n",
      "\tf1:  0.7281722300750245\n",
      "\tprecision:  0.7384419787332408\n",
      "\trecall:  0.7310892768558672\n",
      "\taccuracy:  0.744\n"
     ]
    }
   ],
   "source": [
    "########### SGD Classifier ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# SGD Classifier \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier(loss = \"log_loss\")\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy\n",
    "f1, precision, recall = buildClassifiers(SGDClassifier(loss = \"log_loss\"), X_train, X_test, y_train, y_test )\n",
    "print(\"SGD CLASSIFIER: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "647c3448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION: \n",
      "\tf1:  0.803745654368061\n",
      "\tprecision:  0.8045069337442219\n",
      "\trecall:  0.803629729210678\n",
      "\taccuracy:  0.808\n"
     ]
    }
   ],
   "source": [
    "########### Logistic Regression ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# Logistic Regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(solver = \"saga\")\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy\n",
    "f1, precision, recall = buildClassifiers(LogisticRegression(solver = \"saga\"), X_train, X_test, y_train, y_test )\n",
    "print(\"LOGISTIC REGRESSION: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b73914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCEPTRON: \n",
      "\tf1:  0.7679071628651462\n",
      "\tprecision:  0.7682756852881334\n",
      "\trecall:  0.7679322869165907\n",
      "\taccuracy:  0.768\n"
     ]
    }
   ],
   "source": [
    "########### PERCEPTRON ###########\n",
    "\n",
    "y = list_of_labels\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y)\n",
    "\n",
    "# Perceptron \n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "classifier = Perceptron()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculating and printing f1, precision, recall, accuracy\n",
    "f1, precision, recall = buildClassifiers(Perceptron(), X_train, X_test, y_train, y_test )\n",
    "print(\"PERCEPTRON: \")\n",
    "print(\"\\tf1: \", f1)\n",
    "print(\"\\tprecision: \", precision)\n",
    "print(\"\\trecall: \", recall)\n",
    "print(\"\\taccuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6568ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
